# Reranker显存占用和性能优化详细分析

## 问题1: 为什么reranker模型会占用23G显存，并且耗时很长？

### 显存占用明细（23GB）

| 组件 | 占用 | 说明 |
|------|------|------|
| Reranker模型（4bit量化） | ~5GB | 模型权重 |
| Embedding模型 | ~100-200MB | all-MiniLM-L6-v2 |
| **批处理激活值** | **~10-15GB** | **主要占用源** |
| 内存碎片 | ~1-3GB | PyTorch内存分配器 |
| 其他进程（172014） | ~7GB | 未知进程 |
| **总计** | **~23GB** | 接近GPU1总容量 |

### 激活值占用详细计算

对于4B模型（hidden_size=2560, num_layers=32）：
- 每个token的激活值：`2560 × 4 bytes = 10KB`
- batch_size=16, max_length=1024时：
  - 输入激活值：`16 × 1024 × 10KB ≈ 160MB`
  - 但中间层会累积：
    - Attention机制：`16 × 1024 × 1024 × 4 bytes ≈ 64MB` (attention scores)
    - 32层累积：`160MB × 32 ≈ 5GB`
    - 加上其他中间激活值：**总计约10-15GB**

### 耗时长的原因

1. **逐个处理**：19599个样本，每个都要：
   - API调用（网络延迟：~10-50ms）
   - Rerank推理（模型计算：~100-500ms）
   - 总计：每个样本~110-550ms，19599个样本约36-180分钟

2. **批处理效率低**：
   - batch_size=16可能不是最优
   - max_length=1024过长，增加计算量

3. **同步操作**：
   - CPU-GPU数据传输
   - 每个batch都要等待GPU完成

## 问题2: 如何优化处理速度？

### 已实施的优化

1. ✅ **降低max_length**：1024 → 256（减少75%的激活值占用）
2. ✅ **增加batch_size**：16 → 64（提高吞吐量）
3. ✅ **优化计算流程**：
   - 只获取最后一个token的logits
   - 使用更内存高效的softmax
   - 立即释放中间变量
4. ✅ **Embedding优化**：使用`convert_to_numpy=True`

### 进一步优化建议

1. **动态batch_size**：根据可用内存自动调整
2. **异步处理**：使用多线程/多进程
3. **批量API调用**：一次处理多个查询
4. **缓存机制**：缓存常见查询的结果

## 问题3: 还有什么使用了GPU1的显存？

### GPU1显存占用明细

1. **Reranker模型（4bit量化）**：~5GB
   - 模型权重（量化后）

2. **Embedding模型**：~100-200MB
   - all-MiniLM-L6-v2模型

3. **批处理激活值**：~10-15GB（**主要占用**）
   - Attention机制激活值
   - 中间层激活值
   - 梯度缓存（虽然用了no_grad，但某些操作仍可能保留）

4. **内存碎片**：~1-3GB
   - PyTorch内存分配器产生的碎片

5. **其他进程**：~7GB
   - 进程172014（需要检查是什么进程）

### 优化后的预期占用

优化后（max_length=256, batch_size=64）：
- Reranker模型：~5GB
- Embedding模型：~200MB
- 激活值：~2-4GB（减少约70%）
- 内存碎片：~1GB
- **总计：~8-10GB**（相比23GB减少约60%）
